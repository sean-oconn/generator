# generator
Generates random text based on k-grams of an existing sample
This program was created for a class project. The prompt is as follows:
"The input to the generator will be a source text together with a parameter n which we will call the order of the model. Our output will always begin with the first n characters of the source document. After that point, each additional character is chosen using a random process that is based upon the most recent n-character string in the output, known in linguistics as an n-gram. (In genomics, these are often denoted with parameter k and called k-mers.)

The model for randomly generating the next character in our output will be to determine the number of times the n-gram occurs in the source text, and to mimic the distribution of what character follows those occurrences in the source.

As an example, assume we have an order-2 model and our source text is 

aaabaaacaaadaaabaaabaaac 

We would automatically begin our output with aa. To determine the next character, notice that there are twelve occurrences of aa in the course. (Each aaa represents two separate occurrences.) Of those twelve occurrences, six are immediately followed by another a, three are followed by b, two are followed by c and one by d. So we randomly pick the next character using this distribution, therefore with probablilty 1/2 of picking a, probability 1/4 of picking b, probability 1/6 of picking c and probability 1/12 of picking d.

If we had next picked b by that process, our most recent n-gram is now ab and based on the source text we are sure to next pick a because 100% of the ab occurrences in the source are followed by a. Had we originally picked c as our third character, and thus have ac as the most recent n-gram, we notice that there are two occurrences of ac in the original source. One of those is followed by a and the other occurs at the end of the string. In our model, this means that we should pick a with probability 1/2 and we should consider ourselves at the end of the output with probability 1/2 (in which case, we should not generate and further characters).

The text generated by this language model will be greatly effected by the parameter n. When n is small, the output will seem almost like gibberish; If n were quite large, the output would eventually be identical to the source document. But as n varies in between, we get some interesting texts which are original, though in the style of the source work
"
